{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximilian/anaconda3/envs/ML/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import FI_estimation\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy import ndimage\n",
    "\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample size:  650000\n"
     ]
    }
   ],
   "source": [
    "# regular experimental data\n",
    "type = np.float64\n",
    "x_tr = np.load(\"Data\"+os.sep+\"x_tr.npy\")\n",
    "y_tr = np.load(\"Data\"+os.sep+\"y_tr.npy\")\n",
    "x_tst = np.load(\"Data\"+os.sep+\"x_tst.npy\")\n",
    "delta = 0.3\n",
    "#\n",
    "# crop the positions\n",
    "steps = 13\n",
    "x_tr = x_tr.reshape(steps,50000,1,18,24)\n",
    "y_tr = y_tr.reshape(steps,50000)\n",
    "idx = np.arange(50000)\n",
    "np.random.shuffle(idx)\n",
    "x_tr = x_tr[:,idx]\n",
    "y_tr = y_tr[:,idx]\n",
    "#\n",
    "y_tr = y_tr.reshape(y_tr.shape[0]*y_tr.shape[1])\n",
    "x_tr = x_tr.reshape(x_tr.shape[0]*x_tr.shape[1],1,18,24)\n",
    "print(\"training sample size: \", y_tr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def shuffle_split_data(X, y, ratio=0.5):\n",
    "    arr_rand = np.random.rand(X.shape[0])\n",
    "    split = arr_rand < np.percentile(arr_rand, ratio*100)\n",
    "\n",
    "    X_train = X[split]\n",
    "    y_train = y[split]\n",
    "    X_test =  X[~split]\n",
    "    y_test = y[~split]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "a = x_tr.shape[0]\n",
    "std = np.std(x_tr, axis=0)\n",
    "std[std==0] = 1\n",
    "mean = np.mean(x_tr, axis=0)\n",
    "\n",
    "for i in range(a): \n",
    "    x_tr[i] = (x_tr[i]-mean)/std\n",
    "for i in range(x_tst.shape[0]): \n",
    "    x_tst[i] = (x_tst[i]-mean[0])/std[0]\n",
    "# ###\n",
    "# cf = 4 * (np.max(y_tr)/2)**2\n",
    "# print(\"multiply the output variance with\", cf)\n",
    "# y_tr = y_tr-np.min(y_tr)\n",
    "# y_tr = 2 * ( y_tr / np.max(y_tr) - 0.5 )\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = shuffle_split_data(x_tr, y_tr, ratio=0.8)\n",
    "x_tr = None\n",
    "y_tr = None\n",
    "\n",
    "X_train = X_train.astype(type)\n",
    "Y_train = Y_train.astype(type)\n",
    "X_val = X_val.astype(type)\n",
    "Y_val = Y_val.astype(type)\n",
    "x_tst = x_tst.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7061/1397782601.py:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755832681/work/aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  train_set = TensorDataset(torch.tensor(X_train), torch.tensor(Y_train).T)\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "train_set = TensorDataset(torch.tensor(X_train), torch.tensor(Y_train).T)\n",
    "val_set = TensorDataset(torch.tensor(X_val), torch.tensor(Y_val).T)\n",
    "\n",
    "bs = 128\n",
    "train_loader = Data.DataLoader(train_set, batch_size=bs, shuffle=True)\n",
    "validation_loader = Data.DataLoader(val_set, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(n[0], n[1])\n",
    "        self.linear2 = nn.Linear(n[1], n[2])\n",
    "        self.linear3 = nn.Linear(n[2], n[3])\n",
    "        self.linear4 = nn.Linear(n[3], n[4])\n",
    "        self.linear5 = nn.Linear(n[4], n[5])\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)    \n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear4(x)       \n",
    "        x = F.relu(x)\n",
    "        x = self.linear5(x)  \n",
    "        return x\n",
    "n=[18*24,800,100,25,5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  0 , val=  1.302305463744545 , train =  1.3362887694762988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     39\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 40\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     training_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     42\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/optim/_functional.py:98\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m     97\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmaximum(max_exp_avg_sqs[i], exp_avg_sq, out\u001b[38;5;241m=\u001b[39mmax_exp_avg_sqs[i])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "starting_epoch = 0\n",
    "criterion =  nn.MSELoss()\n",
    "n_epochs = 25\n",
    "lr = 5e-7\n",
    "training_loss = 0.\n",
    "validation_loss = 0.\n",
    "net = Model(n).to(device)\n",
    "all_losses = []\n",
    "all_losses_val = []\n",
    "all_losses.append(training_loss/len(train_loader))\n",
    "all_losses_val.append(validation_loss/len(validation_loader))\n",
    "torch.save(net,  'Models' +os.sep+ 'epoch' + str(0)+'Experimental.pth')\n",
    "\n",
    "for epoch in range(starting_epoch, starting_epoch + n_epochs):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=0.003)\n",
    "    net.train()\n",
    "    training_loss = 0.\n",
    "    validation_loss = 0.\n",
    "    batch_count = 0\n",
    "    for inputs, target in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_count += 1\n",
    "        y_pred = net(inputs)\n",
    "        loss = criterion(y_pred,  torch.unsqueeze(target,dim=1)  )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, target in validation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            y_pred = net(inputs)\n",
    "            loss_val = criterion(y_pred,  torch.unsqueeze(target,dim=1) )\n",
    "            validation_loss += loss_val.item()\n",
    "    print(\"epoch= \", epoch, \", val= \", validation_loss/len(validation_loader),\", train = \", training_loss/len(train_loader))\n",
    "    torch.save(net,   'Models' +os.sep+ 'epoch' + str(epoch+1)+'Experimental.pth')\n",
    "    all_losses_val.append(validation_loss/len(validation_loader))\n",
    "    all_losses.append(training_loss/len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For FI based early stopping, increase the size of the network and decrease the learning rate\n",
    "If y_tr is rescaled then the MSE must be rescaled accordingly in order to be comparable with 1/FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('Plots'+os.sep+'losses_SpaceInvader.npz',\n",
    "#          all_losses=all_losses,\n",
    "#         all_losses_val = all_losses_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tst = x_tst.astype(np.float64)\n",
    "# x_minus = x_tst[0]\n",
    "# x_middle = x_tst[1]\n",
    "# x_plus = x_tst[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape torch.Size([450000, 18, 24])\n",
      "calculating FI\n",
      "up:  0\n",
      "up:  30\n",
      "up:  60\n",
      "LFI didn't increase after the 3rd iteration:  860\n",
      "calculating FI\n",
      "up:  0\n",
      "up:  30\n",
      "up:  60\n",
      "LFI didn't increase after the 3rd iteration:  160\n",
      "calculating FI\n",
      "up:  0\n",
      "up:  30\n",
      "up:  60\n",
      "up:  90\n",
      "up:  120\n",
      "up:  150\n",
      "up:  180\n",
      "Warning: FI calculation did not converge! Increase the parameter lim. Note that large lim might require more data.\n",
      "calculating FI\n",
      "up:  0\n",
      "up:  30\n",
      "up:  60\n",
      "up:  90\n",
      "up:  120\n",
      "up:  150\n",
      "up:  180\n",
      "Warning: FI calculation did not converge! Increase the parameter lim. Note that large lim might require more data.\n",
      "calculating FI\n",
      "up:  0\n",
      "up:  30\n",
      "up:  60\n",
      "up:  90\n",
      "up:  120\n",
      "up:  150\n",
      "up:  180\n",
      "Warning: FI calculation did not converge! Increase the parameter lim. Note that large lim might require more data.\n",
      "[1.60000000e+00 1.16838807e+00 1.72955909e-01 2.78382529e-02\n",
      " 1.47825281e-03 1.78705140e-03]\n",
      "#------------------------------------------------------#\n",
      "calculating FI\n",
      "up:  0\n"
     ]
    }
   ],
   "source": [
    "#------- calculating the FI flow at different epochs\n",
    "#------- parameters entering the algorithm\n",
    "fi_in = 1.6 # input FI should generally be evaluated carefully, possible by visual inspection of the LFI curve\n",
    "kappa = 0.1 # ratio of slopes\n",
    "gamma = 0.05 # stop when the LFI doesn't improve in the first iterations \n",
    "noise = 0.01 # noise added\n",
    "step = 30 # increase of dimensionality\n",
    "upperLimit = 200 # maximum increase \n",
    "n_epochs = 20\n",
    "X = x_tst\n",
    "#X = X.reshape(X.shape[0]*X.shape[1], X.shape[2]) \n",
    "X = torch.tensor(X)\n",
    "print(\"X.shape\", X.shape)\n",
    "fi_array = []\n",
    "for epoch in range(n_epochs):\n",
    "    net = Model(n)\n",
    "    net = torch.load('Models'+os.sep + 'epoch'+ str(epoch)+'Experimental.pth', map_location=torch.device('cpu'))\n",
    "    net.eval()\n",
    "    #------- extract data arrays\n",
    "    return_nodes = {\n",
    "        \"linear1\": \"linear1\",\n",
    "        \"linear2\": \"linear2\",\n",
    "        \"linear3\": \"linear3\",\n",
    "        \"linear4\": \"linear4\"}\n",
    "    model2 = create_feature_extractor(net, return_nodes=return_nodes)\n",
    "    intermediate_outputs = model2(X)\n",
    "    linear1 = intermediate_outputs['linear1']\n",
    "    linear2 = intermediate_outputs['linear2']\n",
    "    linear3 = intermediate_outputs['linear3']\n",
    "    linear4 = intermediate_outputs['linear4']\n",
    "    layer_out = net(X)\n",
    "    #------- reshape arrays\n",
    "    linear1 = linear1.reshape(3 , linear1.shape[0]//3, linear1.shape[1])\n",
    "    linear2 = linear2.reshape(3 , linear2.shape[0]//3, linear2.shape[1])\n",
    "    linear3 = linear3.reshape(3 , linear3.shape[0]//3, linear3.shape[1])\n",
    "    linear4 = linear4.reshape(3 , linear4.shape[0]//3, linear4.shape[1])\n",
    "    layer_out = layer_out.reshape(3 , layer_out.shape[0]//3, layer_out.shape[1])\n",
    "    #------- convert to numpy arrays\n",
    "    linear1 = linear1.detach().numpy()\n",
    "    linear2 = linear2.detach().numpy()\n",
    "    linear3 = linear3.detach().numpy()\n",
    "    linear4 = linear4.detach().numpy()\n",
    "    layer_out = layer_out.detach().numpy()\n",
    "    #------- apply activation function since the data is extracted directly after the linear transformation\n",
    "    linear1 = (FI_estimation.ReLU(linear1))\n",
    "    linear2 = (FI_estimation.ReLU(linear2))\n",
    "    linear3 = (FI_estimation.ReLU(linear3))\n",
    "    linear4 = (FI_estimation.ReLU(linear4))\n",
    "    layer_out = (layer_out)\n",
    "    #------- calculate the FI\n",
    "    fi_1 = FI_estimation.get_FI(linear1, delta, upperLimit, step, kappa, constant_threshold=gamma, noise_factor=noise, biasedLFI=True)\n",
    "    fi_2 = FI_estimation.get_FI(linear2, delta, upperLimit, step, kappa, constant_threshold=gamma, noise_factor=noise, biasedLFI=True)\n",
    "    fi_3 = FI_estimation.get_FI(linear3, delta, upperLimit, step, kappa, constant_threshold=gamma, noise_factor=noise, biasedLFI=True)\n",
    "    fi_4 = FI_estimation.get_FI(linear4, delta, upperLimit, step, kappa, constant_threshold=gamma, noise_factor=noise, biasedLFI=True)\n",
    "    fi_out = FI_estimation.get_FI(layer_out, delta, upperLimit, step, kappa, constant_threshold=gamma, noise_factor=noise, biasedLFI=True)\n",
    "\n",
    "    if isinstance(fi_out, np.ndarray): fi_out = fi_out.item()\n",
    "    fi = np.array([fi_in,fi_1,fi_2,fi_3,fi_4,fi_out])\n",
    "    print(fi)\n",
    "    fi_array.append(fi)\n",
    "    print(\"#------------------------------------------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"Plots\" + os.sep + \"fi_flow_SpaceInvader.npy\", np.array(fi_array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
